{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel , BertForSequenceClassification, AutoModelForSequenceClassification                                                                                 \n",
    "from src.data_load.data_loader_category import load_split_data\n",
    "from torch import nn\n",
    "from torch.optim import SGD\n",
    "from src.model import BertModelClassification, CNN, ModelMixBert\n",
    "from src.train_model import Train\n",
    "from torchvision import models\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 128\n",
    "LEARN_RATE = 0.001\n",
    "EMBEDDING_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader, testloader, model_dataset = load_split_data(datadir='./final.csv', batch_size=BATCH_SIZE, test_size=0.3, data_augmentation=True, BERT = True)\n",
    "tematicas_name = model_dataset.get_tematicas_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_class = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = 17)\n",
    "# model_class.to(device)\n",
    "\n",
    "# for parameter in model_class.parameters():\n",
    "#     parameter.requires_grad = True\n",
    "\n",
    "\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "# for parameter in model.parameters():\n",
    "#     parameter.requires_grad = True\n",
    "\n",
    "model_bert = BertModelClassification(model, 17)\n",
    "\n",
    "# model_ft = models.resnet152(pretrained=True)\n",
    "# for parameter in model_ft.parameters():\n",
    "#     parameter.requires_grad = True\n",
    "\n",
    "# num_ftrs = model_ft.fc.in_features\n",
    "# model_ft.fc = nn.Linear(num_ftrs, 128)\n",
    "# model_ft = model_ft.to(device)\n",
    "\n",
    "\n",
    "# model2 = CNN(128)\n",
    "# model_mix = ModelMixBert(model_ft, model_bert, 256, 17)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer = SGD(model_bert.parameters(), lr=LEARN_RATE, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Train(model_bert, optimizer, criterion,trainloader, testloader, show_matrix=True, epochs=1000, prints_every=100\n",
    ", device=device, classes=tematicas_name, include_text=True, show_metrics=True)\n",
    "experiment.train_bert(include_image=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef45937ad488851cb60f4a7bff200c56b7e8b2e0a568bbaaf74d1885db76de7a"
  },
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
